{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b3f3318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# move X, E, Z, etc into one vector called state\n",
    "\n",
    "# Calculate partical filter --- whatever that is\n",
    "# Estimated partical filter with another NN\n",
    "# Use estimated partical filter to generate posterior for parameters given data.\n",
    "\n",
    "# Collect data\n",
    "# Decide on model\n",
    "# Estimate parameters and compare to data for various numbers of agents\n",
    "# ???\n",
    "# Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55a24afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/emmet/Documents/code/hetero_simulation/lib')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.example_libraries.optimizers import adam, unpack_optimizer_state, pack_optimizer_state\n",
    "from hetero_simulation.archive.agent import log_utility\n",
    "from hetero_simulation.ml.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fce4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", False)\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37cbe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Parameters of wealth distribution\n",
    "A = 0.5\n",
    "B = 0.2\n",
    "\n",
    "# Preference and production parameters\n",
    "alpha = 0.36 # (0, 1)\n",
    "beta = 0.96 # (0, 1)\n",
    "delta = 0.025 # (0, 1)\n",
    "rho_z = 0.95 # (0, 1)\n",
    "rho_e = 0.9 # (0, 1)\n",
    "sigma_z = 0.01 # (0, inf)\n",
    "sigma_e = 0.2 * jnp.sqrt(1 - rho_e**2) # (0, inf)\n",
    "\n",
    "STRUCT_PARAM = {\n",
    "    'alpha': alpha, 'beta': beta, 'delta': delta, 'a': A, 'b': B,\n",
    "    'sigma_z': sigma_z, 'sigma_e': sigma_e, 'rho_z': rho_z, 'rho_e': rho_e\n",
    "}\n",
    "\n",
    "STRUCT_PARAM_IDXS = {k: v for k, v in zip(STRUCT_PARAM.keys(), np.arange(len(STRUCT_PARAM.keys())))}\n",
    "STRUCT_PARAM_ARR = jnp.asarray(np.fromiter(STRUCT_PARAM.values(), dtype=jnp.float32))\n",
    "\n",
    "AGG_IDXS = {'Xs': jnp.array(list(range(5))), 'Es': jnp.array(list(range(5, 10))), 'Zs': jnp.array(list(range(10, 11)))}\n",
    "IDO_IDXS = {'xs': jnp.array(list(range(1))), 'es': jnp.array(list(range(1, 2)))}\n",
    "\n",
    "# Hyper-parameters\n",
    "N = 2 ** 4\n",
    "MB = 2 ** 2\n",
    "N_EPOCH = 250\n",
    "N_ITER = 10 * (N // MB)\n",
    "N_FORWARD = 50\n",
    "T = 200\n",
    "\n",
    "K = 5 # number of agents (~ size of state space)\n",
    "M = 4\n",
    "nn_shapes = jnp.array([M, M, M, M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d77da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def neural_network(model_params, struct_params, agg_state, ido_state):\n",
    "    X_tilde = jnp.concatenate([struct_params.reshape(1, -1),\n",
    "                               agg_state.reshape(1, -1),\n",
    "                               ido_state.reshape(1, -1)], \n",
    "                              axis=1)\n",
    "    X_tilde = X_tilde @ model_params['theta']\n",
    "    # l1 = tanh(X_tilde, model_params['w0'], model_params['b0'])\n",
    "    l2 = tanh(X_tilde, model_params['w1'], model_params['b1'])\n",
    "    l3 = tanh(l2, model_params['w2'], model_params['b2'])\n",
    "    # l4 = tanh(jnp.concatenate((l3, e[..., jnp.newaxis], x[..., jnp.newaxis])), model_params['w3'], model_params['b3'])\n",
    "    return jnp.array([jnp.squeeze(sigmoid(l3, model_params['cwf'], model_params['cbf'])),\n",
    "                      jnp.squeeze(exp(l3, model_params['lwf'], model_params['lbf']))])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def fischer_burmeister(a, b):\n",
    "    return a + b - jnp.sqrt(jnp.power(a, 2) + jnp.power(b, 2))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def next_X(model_params, struct_params, agg_state):\n",
    "    R, W = prices(struct_params, agg_state)\n",
    "    w = jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(agg_state[AGG_IDXS['Xs']], agg_state[AGG_IDXS['Es']]))\n",
    "    ido_state = jnp.concatenate((agg_state[AGG_IDXS['Es']], jnp.squeeze(w))).reshape(K, 2, -1)\n",
    "    out = jax.vmap(neural_network, in_axes=(None, None, None, 0))(model_params, struct_params, agg_state, ido_state)\n",
    "    c = jnp.squeeze(w * out[..., 0])\n",
    "        \n",
    "    return (1 - out[..., 0]) * w\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def prices(struct_params, agg_state):\n",
    "    sumk = jnp.sum(agg_state[AGG_IDXS['Xs']])\n",
    "    sumexpl = jnp.sum(jnp.exp(agg_state[AGG_IDXS['Es']]))\n",
    "    w = (1 - struct_params[STRUCT_PARAM_IDXS['alpha']]) * jnp.exp(agg_state[AGG_IDXS['Zs']]) * jnp.power(sumk, struct_params[STRUCT_PARAM_IDXS['alpha']]) * jnp.power(sumexpl, -1 * struct_params[STRUCT_PARAM_IDXS['alpha']])\n",
    "    r = 1 - struct_params[STRUCT_PARAM_IDXS['delta']] + struct_params[STRUCT_PARAM_IDXS['alpha']] * jnp.exp(agg_state[AGG_IDXS['Zs']]) * jnp.power(sumk, struct_params[STRUCT_PARAM_IDXS['alpha']] - 1) * jnp.power(sumexpl, 1 - struct_params[STRUCT_PARAM_IDXS['alpha']])\n",
    "    return r, w\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def loss(model_params, struct_params, agg_state, key):\n",
    "    X = agg_state[AGG_IDXS['Xs']]\n",
    "    E = agg_state[AGG_IDXS['Es']]\n",
    "    Z = agg_state[AGG_IDXS['Zs']]\n",
    "    \n",
    "    agg_state_1 = next_state(model_params, struct_params, agg_state, key)\n",
    "    R, W = prices(struct_params, agg_state)\n",
    "    w = jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(X, E))\n",
    "    ido_states = jnp.concatenate((agg_state[AGG_IDXS['Es']], w)).reshape(5, 2, -1)\n",
    "    outputs = jax.vmap(neural_network, in_axes=(None, None, None, 0))(model_params, struct_params, agg_state, ido_states)\n",
    "    c_rel = outputs[..., 0]\n",
    "    lm = outputs[..., 1]\n",
    "    c = w * c_rel\n",
    "    \n",
    "    X1 = w - c\n",
    "    E1 = agg_state_1[AGG_IDXS['Es']]\n",
    "    R1, W1 = prices(struct_params, agg_state_1)\n",
    "    \n",
    "    w1 = jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(X1, E1))\n",
    "    ido_states_1 = jnp.concatenate((agg_state_1[AGG_IDXS['Es']], w1)).reshape(5, 2, -1)\n",
    "    c1 = w1 * jax.vmap(neural_network, in_axes=(None, None, None, 0))(model_params, struct_params, agg_state_1, ido_states_1)[..., 0]\n",
    "\n",
    "    u = lambda c: log_utility()(c)\n",
    "    g = jax.vmap(lambda c: struct_params[STRUCT_PARAM_IDXS['beta']] * R1 * jax.grad(u)(c))(c1)\n",
    "    up = jax.vmap(jax.grad(u))(c)\n",
    "    g_diff = jax.vmap(lambda g, up, lm: (g / up) - lm)(g.reshape(-1, 1), up.reshape(-1, 1), lm.reshape(-1, 1))\n",
    "    lm_diff = jax.vmap(lambda c, lm: fischer_burmeister(1 - c, 1 - lm))(c_rel.reshape(-1, 1), lm.reshape(-1, 1))\n",
    "\n",
    "    return g_diff, lm_diff, c_rel\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def batch_loss(model_params, struct_params, agg_states, keys):\n",
    "    g_diff_1, lm_diff_1, c_rels = jax.vmap(loss, in_axes=(None, 0, 0, None))(model_params, struct_params, agg_states, keys[0])\n",
    "    g_diff_2, lm_diff_2, c_rels = jax.vmap(loss, in_axes=(None, 0, 0, None))(model_params, struct_params, agg_states, keys[1])\n",
    "    g2 = g_diff_1 * g_diff_2\n",
    "    lm2 = lm_diff_1 * lm_diff_2\n",
    "\n",
    "    return jnp.squeeze(jnp.mean(g2 + lm2)**2), (jnp.squeeze(jnp.mean(g2)), jnp.squeeze(jnp.mean(lm2)), c_rels)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def next_state(model_params, struct_params, agg_state, key):   \n",
    "    X_prime = next_X(model_params, struct_params, agg_state)\n",
    "    E_prime = struct_params[STRUCT_PARAM_IDXS['rho_e']] * agg_state[AGG_IDXS['Es']] +\\\n",
    "              struct_params[STRUCT_PARAM_IDXS['sigma_e']] * jax.random.normal(key, shape=(K,))\n",
    "    Z_prime = struct_params[STRUCT_PARAM_IDXS['rho_z']] * agg_state[AGG_IDXS['Zs']] +\\\n",
    "              struct_params[STRUCT_PARAM_IDXS['sigma_z']] * jax.random.normal(key)  \n",
    "    \n",
    "    agg_states = jnp.concatenate((X_prime, E_prime, Z_prime))\n",
    "    return agg_states\n",
    "\n",
    "\n",
    "@jax.tree_util.Partial(jax.jit, static_argnums=(4,))\n",
    "def simulate_state_forward(model_params, struct_params, agg_states, key, n_forward=N_FORWARD):\n",
    "    if len(agg_states.shape) == 1:\n",
    "        agg_states = agg_states.reshape(1, -1)\n",
    "    if len(struct_params.shape) == 1:\n",
    "        struct_params = struct_params.reshape(1, -1)\n",
    "    assert agg_states.shape[0] == struct_params.shape[0]\n",
    "\n",
    "    keys = jax.random.split(key, n_forward * agg_states.shape[0]).reshape(n_forward, agg_states.shape[0], 2)\n",
    "    \n",
    "    @jax.jit\n",
    "    def inner_loop(agg_states, i):\n",
    "        return jax.vmap(next_state, in_axes=(None, 0, 0, 0))(model_params, struct_params, agg_states, keys[i]), None\n",
    "    \n",
    "    agg_states, _ = jax.lax.scan(inner_loop, agg_states, jnp.arange(n_forward))\n",
    "    \n",
    "    return jnp.squeeze(agg_states), keys[-1, -1]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def generate_struct_params(key):\n",
    "    keys = jax.random.split(key, 3)\n",
    "    \n",
    "    alpha = jax.random.uniform(keys[0], minval=0.2, maxval=0.5) * jnp.ones(1)\n",
    "    beta = jax.random.uniform(keys[1], minval=0.8, maxval=1.) * jnp.ones(1)\n",
    "    delta = jax.random.uniform(keys[2], minval=0.001, maxval=0.1) * jnp.ones(1)\n",
    "    a = STRUCT_PARAM['a'] * jnp.ones(1)\n",
    "    b = STRUCT_PARAM['b'] * jnp.ones(1)\n",
    "    rho_z = STRUCT_PARAM['rho_z'] * jnp.ones(1)\n",
    "    rho_e = STRUCT_PARAM['rho_e'] * jnp.ones(1)\n",
    "    sigma_z = STRUCT_PARAM['sigma_z'] * jnp.ones(1)\n",
    "    sigma_e = STRUCT_PARAM['sigma_e'] * jnp.ones(1)\n",
    "    \n",
    "    struct_params = jnp.concatenate((alpha, beta, delta, a, b, rho_z, rho_e, sigma_z, sigma_e))\n",
    "        \n",
    "    return struct_params\n",
    "\n",
    "\n",
    "@jax.tree_util.Partial(jax.jit, static_argnums=(2, 3))\n",
    "def generate_random_state(model_params, key, n_forward=N_FORWARD, batch_size=N//2, struct_params=None): \n",
    "    if struct_params is None:\n",
    "        keys = jax.random.split(key, batch_size)\n",
    "        struct_params = jax.vmap(generate_struct_params)(keys)\n",
    "    elif len(struct_params.shape) == 1:\n",
    "        struct_params = struct_params.reshape(1, -1)\n",
    "\n",
    "    samples = struct_params.shape[0]\n",
    "    Zs = jnp.ones(shape=(samples, 1))\n",
    "    Es = jnp.ones(shape=(samples, K))\n",
    "    Xs = jnp.exp(STRUCT_PARAM['a'] * jax.random.normal(\n",
    "        jax.random.PRNGKey(np.random.randint(1, int(1e8))), \n",
    "        shape=(samples, K))) + STRUCT_PARAM['b']\n",
    "    \n",
    "    agg_states = jnp.concatenate((Xs, Es, Zs), axis=1)\n",
    " \n",
    "    assert struct_params.shape[0] == agg_states.shape[0]\n",
    "    if n_forward > 0:\n",
    "        agg_states, key = simulate_state_forward(model_params, struct_params, agg_states, key, n_forward=n_forward)\n",
    "        \n",
    "    return agg_states, struct_params, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "838148e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.5\n",
    "init_keys = jax.random.split(jax.random.PRNGKey(5), 11)\n",
    "theta0 = jax.random.gamma(init_keys[0], scale, shape=(2 * K + 3 + len(STRUCT_PARAM.values()), nn_shapes[0]))\n",
    "w00 = scale * jax.random.normal(init_keys[1], shape=(2 * K + 3 + len(STRUCT_PARAM.values()), nn_shapes[0]))\n",
    "w01 = scale * jax.random.normal(init_keys[2], shape=(nn_shapes[0], nn_shapes[1]))\n",
    "w02 = scale * jax.random.normal(init_keys[3], shape=(nn_shapes[1], nn_shapes[2]))\n",
    "w03 = scale * jax.random.normal(init_keys[4], shape=(nn_shapes[2] + 2, nn_shapes[3]))\n",
    "w0f = scale * jax.random.normal(init_keys[5], shape=(nn_shapes[1], 1))\n",
    "b00 = scale * jax.random.normal(init_keys[6], shape=(1, nn_shapes[0]))\n",
    "b01 = scale * jax.random.normal(init_keys[7], shape=(1, nn_shapes[1]))\n",
    "b02 = scale * jax.random.normal(init_keys[8], shape=(1, nn_shapes[2]))\n",
    "b03 = scale * jax.random.normal(init_keys[9], shape=(1, nn_shapes[3]))\n",
    "b0f = scale * jax.random.normal(init_keys[10], shape=(1, 1))\n",
    "\n",
    "params0 = {\n",
    "    'theta': theta0, 'w0': w00, 'w1': w01, 'w2': w02, 'w3': w03, 'cwf': w0f, 'lwf': w0f, 'b0': b00, 'b1': b01, 'b2': b02, 'b3': b03, 'cbf': b0f, 'lbf': b0f\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3cd0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(opt_state, tol=1e-10, max_iter=10**4, rand_struct_params=True):\n",
    "    j = 0\n",
    "    key = jax.random.PRNGKey(np.random.randint(1, int(1e8)))\n",
    "    val_loss = jnp.inf\n",
    "    grad = {'0': jnp.inf}\n",
    "    opt_init, opt_update, get_params = adam(step_size=0.001)\n",
    "    model_params = get_params(opt_state)\n",
    "\n",
    "    if rand_struct_params:\n",
    "        agg_states, struct_params, key = generate_random_state(model_params, key)\n",
    "    else:\n",
    "        agg_states, struct_params, key = generate_random_state(model_params, key, struct_params=jnp.repeat(jnp.asarray(list(STRUCT_PARAM.values()))[jnp.newaxis], (N // 2), axis=0))\n",
    "\n",
    "    while j < max_iter and max([jnp.max(jnp.abs(v)) for k, v in grad.items()]) > tol and jnp.abs(val_loss) > tol:\n",
    "        jj = 0\n",
    "        while jj < N_ITER:\n",
    "            keys = jax.random.split(key, 2)\n",
    "            key = keys[-1]\n",
    "            model_params = get_params(opt_state)\n",
    "\n",
    "            sample = jax.random.choice(jax.random.PRNGKey(np.random.randint(1, int(1e8))), jnp.arange(N // 2), shape=(2, MB // 2,))\n",
    "            val, grad = jax.value_and_grad(batch_loss, has_aux=True)(model_params, struct_params[sample[0]], agg_states[sample[1]], keys)\n",
    "            val_loss = jnp.abs(val[0])\n",
    "            c_star_rel = val[1][-1]\n",
    "            if not (c_star_rel < 1).all():\n",
    "                print(jnp.concatenate((c_star_rel, struct_params[sample[0], :3]), axis=1))\n",
    "                raise ValueError('Invalid consumption choices observed') \n",
    "            if jnp.isnan(val_loss):\n",
    "                raise ValueError('Loss is nan')\n",
    "\n",
    "            c_val = jnp.abs(val[1][0])\n",
    "            kt_val = jnp.abs(val[1][1])\n",
    "            opt_state = opt_update(j * N_ITER + jj, grad, opt_state)\n",
    "\n",
    "            jj += 1\n",
    "\n",
    "        # Start from a new random position, before moving into the current implied ergodic set\n",
    "        model_params = get_params(opt_state)\n",
    "        if N_FORWARD > 0:\n",
    "            if rand_struct_params:\n",
    "                agg_states, struct_params, key = generate_random_state(model_params, key)\n",
    "            else:\n",
    "                agg_states, struct_params, key = generate_random_state(model_params, key, struct_params=jnp.repeat(jnp.asarray(list(STRUCT_PARAM.values()))[jnp.newaxis], (N // 2), axis=0))\n",
    "\n",
    "        if j % 1 == 0:\n",
    "            trained_params = unpack_optimizer_state(opt_state)\n",
    "            # pickle.dump(trained_params, open(f'./ks_cont_models/ks_cont_model_{K}_{j}.pkl', 'wb'))\n",
    "            print(f'Iteration: {j}  Total Loss: {val_loss:.2e}  C Loss: {c_val:.2e}  KT Loss: {kt_val:.2e}' +\\\n",
    "                  f'  Max Grad: {max([jnp.max(jnp.abs(v)) for k, v in grad.items()]):.2e}' +\\\n",
    "                  f'  Max Param: {max([jnp.max(jnp.abs(v)) for k, v in model_params.items()]):.2e}')\n",
    "        j += 1\n",
    "        \n",
    "    return opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59afa208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-fit model\n",
    "opt_init, opt_update, get_params = adam(step_size=0.001)\n",
    "saved_params = pickle.load(open(f'./ks_cont_models/ks_cont_model_{K}_central.pkl', 'rb'))\n",
    "central_opt_state = pack_optimizer_state(saved_params)\n",
    "central_params = get_params(central_opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd0e448",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opt_init, opt_update, get_params = adam(step_size=0.001)\n",
    "# opt_state = opt_init(params0)\n",
    "\n",
    "# central_opt_state = training_loop(opt_state, max_iter=N_EPOCH, rand_struct_params=False)\n",
    "# central_params = get_params(central_opt_state)\n",
    "# pickle.dump(unpack_optimizer_state(central_opt_state), open(f'./ks_cont_models/ks_cont_model_{K}_central.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60be261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-fit model\n",
    "range_opt_init, opt_update, get_params = adam(step_size=0.001)\n",
    "range_saved_params = pickle.load(open(f'./ks_cont_models/ks_cont_model_{K}_range.pkl', 'rb'))\n",
    "range_opt_state = pack_optimizer_state(range_saved_params)\n",
    "range_params = get_params(range_opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b0b1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_opt_state = training_loop(opt_state, max_iter=N_EPOCH, rand_struct_params=True)\n",
    "# range_params = get_params(range_opt_state)\n",
    "# pickle.dump(unpack_optimizer_state(range_opt_state), open(f'./ks_cont_models/ks_cont_model_{K}_range.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d922f",
   "metadata": {},
   "source": [
    "### Experimental: SMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c16dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = jax.random.PRNGKey(123)\n",
    "# # Note we draw from the ergodic distribution, but which parameters should we use to do this?\n",
    "# train_agg_states, train_struct_params, key = generate_random_state(params0, key, struct_params=None)\n",
    "# true_struct_params = jnp.repeat(jnp.asarray(list(STRUCT_PARAM.values()))[jnp.newaxis], N // 2, axis=0)\n",
    "# Rs, Ws = jax.vmap(prices)(train_struct_params, train_agg_states)\n",
    "# ws = jax.vmap(lambda agg_state, R, W: jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(agg_state[AGG_IDXS['Xs']], agg_state[AGG_IDXS['Es']])))(train_agg_states, Rs, Ws)\n",
    "# ido_states = jnp.squeeze(jax.vmap(lambda w, agg_state: jnp.concatenate((agg_state[AGG_IDXS['Es']], jnp.squeeze(w))).reshape(5, 2, -1))(ws, train_agg_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689e8ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_preds = jax.vmap(jax.vmap(neural_network, in_axes=(None, None, None, 0)), in_axes=(None, 0, 0, 0))(central_params, true_struct_params, train_agg_states, ido_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb9c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# range_preds = jax.vmap(jax.vmap(jax.vmap(neural_network, in_axes=(None, None, None, 0)), in_axes=(None, None, 0, 0)), in_axes=(None, 0, None, None))(range_params, train_struct_params, train_agg_states, ido_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c489499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffs = jnp.mean(jax.vmap(\n",
    "#                     jax.vmap(\n",
    "#                         jax.vmap(lambda true_pred, range_pred: true_pred - range_pred, \n",
    "#                                  in_axes=(0, 0)), \n",
    "#                         in_axes=(0, 0)), \n",
    "#                     in_axes=(None, 0))(true_preds, range_preds), axis=(1, 2))\n",
    "# log_liks = jax.scipy.stats.multivariate_normal.logpdf(diffs, mean=jnp.ones(2), cov=jnp.diag(jnp.ones(2) / MB))\n",
    "# log_liks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee5a6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "# def diff_fn(train_struct_params):\n",
    "#     true_preds = jax.vmap(jax.vmap(neural_network, in_axes=(None, None, None, 0)), in_axes=(None, 0, 0, 0))(central_params, true_struct_params, train_agg_states, ido_states)\n",
    "#     range_preds = jax.vmap(jax.vmap(jax.vmap(neural_network, in_axes=(None, None, None, 0)), in_axes=(None, None, 0, 0)), in_axes=(None, 0, None, None))(range_params, train_struct_params, train_agg_states, ido_states)\n",
    "#     diffs = jnp.mean(jax.vmap(\n",
    "#                     jax.vmap(\n",
    "#                         jax.vmap(lambda true_pred, range_pred: true_pred - range_pred, \n",
    "#                                  in_axes=(0, 0)), \n",
    "#                         in_axes=(0, 0)), \n",
    "#                     in_axes=(None, 0))(true_preds, range_preds), axis=(1, 2))\n",
    "#     return diffs[:, 0]\n",
    "\n",
    "# grads = jax.jacfwd(diff_fn)(train_struct_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cadf0",
   "metadata": {},
   "source": [
    "### Particle Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f810ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(123)\n",
    "# Note we draw from the ergodic distribution, but which parameters should we use to do this?\n",
    "train_agg_states, train_struct_params, key = generate_random_state(params0, key, struct_params=None)\n",
    "true_struct_params = jnp.repeat(jnp.asarray(list(STRUCT_PARAM.values()))[jnp.newaxis], N // 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83cad3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([0.36      , 0.96      , 0.025     , 0.5       , 0.2       ,\n",
       "             0.01      , 0.08717798, 0.95      , 0.9       ],            dtype=float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_struct_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0a0aabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.36,\n",
       " 'beta': 0.96,\n",
       " 'delta': 0.025,\n",
       " 'a': 0.5,\n",
       " 'b': 0.2,\n",
       " 'sigma_z': 0.01,\n",
       " 'sigma_e': DeviceArray(0.08717798, dtype=float64, weak_type=True),\n",
       " 'rho_z': 0.95,\n",
       " 'rho_e': 0.9}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STRUCT_PARAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8d4e69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[2.33356122, 1.72686798, 2.04898146, 2.12889787, 2.00632565],\n",
       "             [2.29498955, 1.76358494, 2.12650499, 2.14621786, 1.99111546],\n",
       "             [2.299148  , 1.79381567, 2.20908629, 2.15982813, 1.97093196],\n",
       "             [2.26763697, 1.84500548, 2.27020786, 2.16431096, 1.94505641],\n",
       "             [2.25419106, 1.8754396 , 2.3148487 , 2.1615693 , 1.95199953]],            dtype=float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate data from the \"true\" model to use as data for the particle filter\n",
    "t_burn = 200\n",
    "key = jax.random.PRNGKey(235)\n",
    "struct_params = true_struct_params[0]\n",
    "init_state, _, key = generate_random_state(central_params, key, n_forward=500, struct_params=struct_params)\n",
    "\n",
    "\n",
    "def next_states(carry, xs=None):\n",
    "    states, key = carry\n",
    "    next_state, new_key = simulate_state_forward(central_params, struct_params, states, key, n_forward=1)\n",
    "    R, W = prices(true_struct_params[0], states)\n",
    "    w = jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(states[AGG_IDXS['Xs']], states[AGG_IDXS['Es']]))    \n",
    "    ido_states = jnp.squeeze(jnp.concatenate((states[AGG_IDXS['Es']], w)).reshape(K, 2))\n",
    "    preds = jax.vmap(neural_network, in_axes=(None, None, None, 0))(central_params, struct_params, states, ido_states)\n",
    "    return (next_state, new_key), w * preds[..., 0]\n",
    "    \n",
    "init_carry = (init_state, key)\n",
    "_, cs = jax.lax.scan(next_states, init_carry, xs=None, length=T+t_burn)\n",
    "cs = cs[t_burn:]\n",
    "cs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f802140b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(jnp.sum(cs, axis=1)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea045a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HS\n",
    "# @jax.jit\n",
    "# def multinomial(states, weights, key):\n",
    "#     return states[jax.random.categorical(key, jnp.log(weights), shape=(weights.shape[0],))]\n",
    "\n",
    "\n",
    "# FVRR\n",
    "@jax.jit\n",
    "def multinomial(states, weights, key):\n",
    "    idxs = jax.random.categorical(key, weights, shape=(weights.shape[0],))\n",
    "    return states[idxs], weights[idxs]\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_inc_weights(pred_ys, real_y, std=1.):\n",
    "    return jax.vmap(lambda pred_y: \n",
    "                    jax.scipy.stats.multivariate_normal.pdf(pred_y - real_y, \n",
    "                                                            mean=jnp.zeros(real_y.shape[0]),\n",
    "                                                            cov=std*jnp.diag(jnp.ones(real_y.shape[0]))))(pred_ys)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def get_observables(model_params, struct_params, states):\n",
    "    # TODO: Confirm shapes are correct, should vmap states over 1...M\n",
    "    Rs, Ws = jax.vmap(prices, in_axes=(None, 0))(struct_params, states)\n",
    "    ws = jax.vmap(lambda state, R, W: jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(state[AGG_IDXS['Xs']], state[AGG_IDXS['Es']])))(states, Rs, Ws)    \n",
    "    ido_states = jnp.squeeze(jax.vmap(lambda w, state: jnp.concatenate((state[AGG_IDXS['Es']], jnp.squeeze(w))).reshape(K, 2, -1))(ws, states))\n",
    "    range_preds = jax.vmap(jax.vmap(neural_network, in_axes=(None, None, None, 0)), in_axes=(None, None, 0, 0))(model_params, struct_params, states, ido_states)\n",
    "    observables = ws * range_preds[..., 0] # Assume only consumption is visible, for now\n",
    "    return observables\n",
    "\n",
    "\n",
    "# Herbst and Schorfheide\n",
    "# @jax.jit\n",
    "# def particle_loop(model_params, struct_params, data, std, carry, t):\n",
    "#     states, weights, key = carry\n",
    "#     keys = jax.random.split(key, states.shape[0])\n",
    "    \n",
    "#     new_states, new_keys = jax.vmap(simulate_state_forward, in_axes=(None, None, 0, 0, None))(model_params, struct_params, states, keys, 1)\n",
    "#     pred_ys = get_observables(model_params, struct_params, new_states)\n",
    "#     inc_weights = get_inc_weights(pred_ys, data[t], std=std)\n",
    "    \n",
    "#     sum_weights = jnp.mean(inc_weights * weights)\n",
    "#     norm_weights = (inc_weights * weights) / sum_weights\n",
    "    \n",
    "#     ess = (weights.shape[0]) / jnp.sum(inc_weights**2)\n",
    "#     rho = jnp.int32(ess < (weights.shape[0]) / 2)\n",
    "    \n",
    "#     out_states = rho * multinomial(new_states, norm_weights, key) + (1 - rho) * new_states\n",
    "#     out_weights = rho * jnp.ones(weights.shape[0]) + (1 - rho) * norm_weights\n",
    "    \n",
    "#     carry = (out_states, out_weights, new_keys[-1])\n",
    "#     return carry, (out_states, weights, inc_weights)\n",
    "\n",
    "\n",
    "# Fernandez-Villaverde and Rubio-Ramirez\n",
    "@jax.jit\n",
    "def particle_loop(model_params, struct_params, data, std, carry, t):\n",
    "    states, weights, key = carry\n",
    "    keys = jax.random.split(key, states.shape[0])\n",
    "    \n",
    "    new_states, new_keys = jax.vmap(simulate_state_forward, in_axes=(None, None, 0, 0, None))(model_params, struct_params, states, keys, 1)\n",
    "    pred_ys = get_observables(model_params, struct_params, new_states)\n",
    "    inc_weights = get_inc_weights(pred_ys, data[t], std=std)\n",
    "    \n",
    "    sum_weights = jnp.mean(inc_weights)\n",
    "    norm_weights = (inc_weights) / sum_weights\n",
    "    \n",
    "    out_states, out_weights = multinomial(new_states, norm_weights, key)\n",
    "    \n",
    "    carry = (out_states, out_weights, new_keys[-1])\n",
    "    return carry, inc_weights\n",
    "\n",
    "\n",
    "@jax.tree_util.Partial(jax.jit, static_argnums=(5, 6))\n",
    "def particle_filter(model_params, struct_params, data, key, std=1., batch_size=2**9, t_burn=50):\n",
    "    '''\n",
    "    model_params: 1 example of model params, fit over a range of structural parameters\n",
    "    struct_params: 1 example of structural params\n",
    "    data: a DeviceArray([T,]) of data to match observables from model \n",
    "    key: a jax.random.PRNGKey\n",
    "    '''\n",
    "    init_states, _, key = generate_random_state(model_params, key, struct_params=jnp.repeat(struct_params.reshape(1, -1), batch_size, axis=0), n_forward=0)\n",
    "    init_weights = jnp.ones(batch_size)\n",
    "    # states and weights are a batch of M = N // 2 we will average over but there is only one example of \"struct_params\"\n",
    "    inner_loop = jax.tree_util.Partial(particle_loop, model_params, struct_params, data, std)\n",
    "    # Herbst and Schorfheide\n",
    "    # _, (states, weights, inc_weights) = jax.lax.scan(inner_loop, (init_states, init_weights, key), jnp.arange(T))\n",
    "    # ll = jnp.sum(jnp.log(jnp.mean(inc_weights * weights, axis=1)))\n",
    "    \n",
    "    # Fernandez-Villaverde and Rubio-Ramirez\n",
    "    _, inc_weights = jax.lax.scan(inner_loop, (init_states, init_weights, key), jnp.arange(T))\n",
    "    ll = jnp.mean(jnp.log(jnp.mean(inc_weights[t_burn:], axis=1)))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2c213be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(-4.86352015, dtype=float64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LL of true parameters, using true model\n",
    "true_ll = particle_filter(central_params, true_struct_params[0], cs, key, std=1.)\n",
    "true_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3afeb674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([-5.29725333, -5.37620012, -5.3432726 , -5.33386716,\n",
       "             -5.31751722, -5.45214993, -5.36820649, -5.32992951,\n",
       "             -5.38698602, -5.34046039, -5.29955243, -5.25916698,\n",
       "             -5.37968627, -5.41937003, -5.41583416, -5.41783327,\n",
       "             -5.3003913 , -5.26099896, -5.26623531, -5.42280344,\n",
       "             -5.30519301, -5.31793879, -5.39046621, -5.30008633,\n",
       "             -5.43747972, -5.36962521, -5.27311578, -5.27750904,\n",
       "             -5.30052595, -5.33075774, -5.27368304, -5.40655427],            dtype=float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LL of some random parameters, using model fit over range of parameters\n",
    "key  = jax.random.PRNGKey(1)\n",
    "agg_states, struct_params, key = generate_random_state(range_params, key, n_forward=0, batch_size=32, struct_params=None)\n",
    "keys = jax.random.split(key, struct_params.shape[0])\n",
    "lls = jax.vmap(particle_filter, in_axes=(None, 0, None, 0, None))(range_params, struct_params, cs, keys, 1.)\n",
    "lls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32fb120",
   "metadata": {},
   "source": [
    "### Particle Filter Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "203fd878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated: 10\n",
      "Samples generated: 20\n",
      "Samples generated: 30\n",
      "Samples generated: 40\n",
      "Samples generated: 50\n",
      "Samples generated: 60\n",
      "Samples generated: 70\n",
      "Samples generated: 80\n",
      "Samples generated: 90\n",
      "Samples generated: 100\n"
     ]
    }
   ],
   "source": [
    "# Generate a fixed dataset against which to fit the particle filter nn\n",
    "data_size = 100\n",
    "batch_size = 10\n",
    "key = jax.random.PRNGKey(825)\n",
    "agg_states, struct_params, key = generate_random_state(range_params, key, n_forward=0, batch_size=data_size, struct_params=None)\n",
    "keys = jax.random.split(key, struct_params.shape[0])\n",
    "\n",
    "# Hold all but one of the params fixed at their true value\n",
    "# struct_params = struct_params.at[:, 0].set(STRUCT_PARAM['alpha'])\n",
    "struct_params = struct_params.at[:, 1].set(STRUCT_PARAM['beta'])\n",
    "struct_params = struct_params.at[:, 2].set(STRUCT_PARAM['delta'])\n",
    "\n",
    "\n",
    "lls = jnp.array([])\n",
    "samples = 0\n",
    "# Split this task into pieces, as the vmap takes too much memory to do in one chunk\n",
    "while samples < data_size:\n",
    "    ll = jax.vmap(particle_filter, in_axes=(None, 0, None, 0))(range_params, struct_params[samples:samples+batch_size], cs, keys[samples:samples+batch_size])\n",
    "    lls = jnp.concatenate((lls, ll))\n",
    "    samples += batch_size\n",
    "    print(f'Samples generated: {samples}')\n",
    "\n",
    "assert not jnp.isnan(lls).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "33eb6c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f3ddf42a310>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2304x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(32, 6))\n",
    "df = pd.DataFrame(jnp.concatenate((struct_params[:, :3], lls.reshape(-1, 1)), axis=1), columns=['alpha', 'beta', 'delta', 'log-likelihood'])\n",
    "df.plot(kind='scatter', x='alpha', y='log-likelihood', ax=axes[0])\n",
    "df.plot(kind='scatter', x='beta', y='log-likelihood', ax=axes[1])\n",
    "df.plot(kind='scatter', x='delta', y='log-likelihood', ax=axes[2])\n",
    "\n",
    "axes[0].axvline(x=STRUCT_PARAM['alpha'], linewidth=2, color='k')\n",
    "axes[1].axvline(x=STRUCT_PARAM['beta'],  linewidth=2, color='k')\n",
    "axes[2].axvline(x=STRUCT_PARAM['delta'], linewidth=2, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cebc5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.5\n",
    "init_keys = jax.random.split(jax.random.PRNGKey(65), 8)\n",
    "\n",
    "w00 = scale * jax.random.normal(init_keys[0], shape=(true_struct_params[0].shape[0], nn_shapes[0]))\n",
    "w01 = scale * jax.random.normal(init_keys[1], shape=(nn_shapes[0], nn_shapes[1]))\n",
    "w02 = scale * jax.random.normal(init_keys[2], shape=(nn_shapes[1], nn_shapes[2]))\n",
    "w0f = scale * jax.random.normal(init_keys[3], shape=(nn_shapes[1], 1))\n",
    "b00 = scale * jax.random.normal(init_keys[4], shape=(1, nn_shapes[0]))\n",
    "b01 = scale * jax.random.normal(init_keys[5], shape=(1, nn_shapes[1]))\n",
    "b02 = scale * jax.random.normal(init_keys[6], shape=(1, nn_shapes[2]))\n",
    "b0f = scale * jax.random.normal(init_keys[7], shape=(1, 1))\n",
    "\n",
    "pf_params0 = {\n",
    "    'w0': w00, 'w1': w01, 'w2': w02, 'wf': w0f, 'b0': b00, 'b1': b01, 'b2': b02, 'bf': b0f\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9eb79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def particle_neural_network(params, struct_params):\n",
    "    l1 = tanh(struct_params, params['w0'], params['b0'])\n",
    "    l2 = tanh(l1, params['w1'], params['b1'])\n",
    "    l3 = tanh(l2, params['w2'], params['b2'])\n",
    "    return linear(l3, params['wf'], params['bf'])\n",
    "\n",
    "\n",
    "@jax.tree_util.Partial(jax.jit, static_argnums=(5,))\n",
    "def pf_loss(params, model_params, struct_params, data, key, particles):\n",
    "    pf_ll = particle_filter(model_params, struct_params, data, key, batch_size=particles)\n",
    "    nn_ll = particle_neural_network(params, struct_params)\n",
    "\n",
    "    return (nn_ll - pf_ll) ** 2\n",
    "\n",
    "\n",
    "@jax.tree_util.Partial(jax.jit, static_argnums=(5,))\n",
    "def pf_batch_loss(params, model_params, struct_params, data, keys, particles=128):\n",
    "    losses = jax.vmap(pf_loss, in_axes=(None, None, 0, None, 0, None))(params, model_params, struct_params, data, keys, particles)\n",
    "    losses = jnp.nan_to_num(losses, jnp.mean(losses))\n",
    "    return jnp.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7c9de10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(11034102.19640663, dtype=float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(1)\n",
    "agg_states, struct_params, key = generate_random_state(range_params, key, n_forward=0, batch_size=32, struct_params=None)\n",
    "pf_batch_loss(pf_params0, range_params, struct_params, cs, jax.random.split(jax.random.PRNGKey(1), struct_params.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5860e5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100\tPolicy Loss: 3.41e-04\tParticle Filter Loss: inf\n",
      "Iteration: 101\tPolicy Loss: 1.00e-04\tParticle Filter Loss: inf\n",
      "Iteration: 102\tPolicy Loss: 6.13e-04\tParticle Filter Loss: 1.08e+07\n",
      "Iteration: 103\tPolicy Loss: 4.62e-04\tParticle Filter Loss: 1.08e+07\n",
      "Iteration: 104\tPolicy Loss: 2.36e-04\tParticle Filter Loss: 1.08e+07\n",
      "Iteration: 105\tPolicy Loss: 2.00e-04\tParticle Filter Loss: 1.08e+07\n",
      "Iteration: 106\tPolicy Loss: 3.18e-04\tParticle Filter Loss: 1.07e+07\n",
      "Iteration: 107\tPolicy Loss: 3.72e-04\tParticle Filter Loss: 1.07e+07\n",
      "Iteration: 108\tPolicy Loss: 1.70e-04\tParticle Filter Loss: 1.06e+07\n",
      "Iteration: 109\tPolicy Loss: 2.08e-04\tParticle Filter Loss: 1.06e+07\n",
      "Iteration: 110\tPolicy Loss: 4.17e-04\tParticle Filter Loss: 1.05e+07\n",
      "Iteration: 111\tPolicy Loss: 2.68e-04\tParticle Filter Loss: 1.05e+07\n",
      "Iteration: 112\tPolicy Loss: 6.08e-04\tParticle Filter Loss: 1.04e+07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIteration: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mPolicy Loss: \u001b[39m\u001b[39m{\u001b[39;00mpl_loss\u001b[39m:\u001b[39;00m\u001b[39m.2e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mParticle Filter Loss: \u001b[39m\u001b[39m{\u001b[39;00mpf_loss\u001b[39m:\u001b[39;00m\u001b[39m.2e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m get_params(pf_opt_state), get_params(pl_opt_state)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m pf_params, pl_params \u001b[39m=\u001b[39m pf_training_loop(pf_params0, range_params, cs)\n",
      "\u001b[1;32m/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb Cell 27\u001b[0m in \u001b[0;36mpf_training_loop\u001b[0;34m(pf_params, pl_params, data, tol, max_iter, batch_size, particles)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m pl_params \u001b[39m=\u001b[39m pl_get_params(pl_opt_state)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m pf_params \u001b[39m=\u001b[39m pf_get_params(pf_opt_state)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m pf_loss, pf_grad \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvalue_and_grad(pf_batch_loss)(pf_params, pl_params, struct_params, data, keys[batch_size:\u001b[39m2\u001b[39;49m\u001b[39m*\u001b[39;49mbatch_size], particles\u001b[39m=\u001b[39;49mparticles)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mif\u001b[39;00m jnp\u001b[39m.\u001b[39misnan(pf_loss) \u001b[39mor\u001b[39;00m \u001b[39many\u001b[39m([jnp\u001b[39m.\u001b[39misnan(x)\u001b[39m.\u001b[39many() \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m pf_grad\u001b[39m.\u001b[39mvalues()]):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/emmet/Documents/code/hetero_simulation/share/notebooks/ks_extended_estimation.ipynb#X34sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mParticle Filter Loss was nan\u001b[39m\u001b[39m'\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/api.py:995\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    993\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    994\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 995\u001b[0m   ans, vjp_py \u001b[39m=\u001b[39m _vjp(f_partial, \u001b[39m*\u001b[39;49mdyn_args, reduce_axes\u001b[39m=\u001b[39;49mreduce_axes)\n\u001b[1;32m    996\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   ans, vjp_py, aux \u001b[39m=\u001b[39m _vjp(\n\u001b[1;32m    998\u001b[0m       f_partial, \u001b[39m*\u001b[39mdyn_args, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_axes\u001b[39m=\u001b[39mreduce_axes)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/api.py:2457\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2456\u001b[0m   flat_fun, out_tree \u001b[39m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2457\u001b[0m   out_primal, out_vjp \u001b[39m=\u001b[39m ad\u001b[39m.\u001b[39;49mvjp(\n\u001b[1;32m   2458\u001b[0m       flat_fun, primals_flat, reduce_axes\u001b[39m=\u001b[39;49mreduce_axes)\n\u001b[1;32m   2459\u001b[0m   out_tree \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m   2460\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/interpreters/ad.py:130\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvjp\u001b[39m(traceable, primals, has_aux\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, reduce_axes\u001b[39m=\u001b[39m()):\n\u001b[1;32m    129\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 130\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[39m=\u001b[39m linearize(traceable, \u001b[39m*\u001b[39;49mprimals)\n\u001b[1;32m    131\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[39m=\u001b[39m linearize(traceable, \u001b[39m*\u001b[39mprimals, has_aux\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/interpreters/ad.py:119\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m _, in_tree \u001b[39m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    118\u001b[0m jvpfun_flat, out_tree \u001b[39m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 119\u001b[0m jaxpr, out_pvals, consts \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39;49mtrace_to_jaxpr_nounits(jvpfun_flat, in_pvals)\n\u001b[1;32m    120\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[39m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    121\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(out_primal_pval\u001b[39m.\u001b[39mis_known() \u001b[39mfor\u001b[39;00m out_primal_pval \u001b[39min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/profiler.py:206\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    205\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    207\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/interpreters/partial_eval.py:616\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39mwith\u001b[39;00m core\u001b[39m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[39m=\u001b[39mcurrent_name_stack) \u001b[39mas\u001b[39;00m main:\n\u001b[1;32m    615\u001b[0m   fun \u001b[39m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 616\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39;49mcall_wrapped(pvals)\n\u001b[1;32m    617\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m env\n\u001b[1;32m    618\u001b[0m   \u001b[39mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/linear_util.py:168\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    169\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    173\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    174\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/api.py:473\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m   in_type \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39minfer_lambda_input_type(\u001b[39mNone\u001b[39;00m, args_flat)\n\u001b[1;32m    472\u001b[0m   flat_fun \u001b[39m=\u001b[39m lu\u001b[39m.\u001b[39mannotate(flat_fun, in_type)\n\u001b[0;32m--> 473\u001b[0m out_flat \u001b[39m=\u001b[39m xla\u001b[39m.\u001b[39;49mxla_call(\n\u001b[1;32m    474\u001b[0m     flat_fun, \u001b[39m*\u001b[39;49margs_flat,\n\u001b[1;32m    475\u001b[0m     device\u001b[39m=\u001b[39;49mdevice, backend\u001b[39m=\u001b[39;49mbackend, name\u001b[39m=\u001b[39;49mflat_fun\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    476\u001b[0m     donated_invars\u001b[39m=\u001b[39;49mdonated_invars, inline\u001b[39m=\u001b[39;49minline, keep_unused\u001b[39m=\u001b[39;49mkeep_unused)\n\u001b[1;32m    477\u001b[0m out_pytree_def \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m    478\u001b[0m out \u001b[39m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1765\u001b[0m, in \u001b[0;36mCallPrimitive.bind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, fun, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m-> 1765\u001b[0m   \u001b[39mreturn\u001b[39;00m call_bind(\u001b[39mself\u001b[39;49m, fun, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1781\u001b[0m, in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1779\u001b[0m tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(top_trace\u001b[39m.\u001b[39mfull_raise, args)\n\u001b[1;32m   1780\u001b[0m fun_ \u001b[39m=\u001b[39m lu\u001b[39m.\u001b[39mannotate(fun_, fun\u001b[39m.\u001b[39min_type)\n\u001b[0;32m-> 1781\u001b[0m outs \u001b[39m=\u001b[39m top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params)\n\u001b[1;32m   1782\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, apply_todos(env_trace_todo(), outs))\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/interpreters/ad.py:335\u001b[0m, in \u001b[0;36mJVPTrace.process_call\u001b[0;34m(self, call_primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    333\u001b[0m new_params \u001b[39m=\u001b[39m update_params(params, nz_tangents) \u001b[39mif\u001b[39;00m update_params \u001b[39melse\u001b[39;00m params\n\u001b[1;32m    334\u001b[0m f_jvp \u001b[39m=\u001b[39m _update_annotation(f_jvp, f\u001b[39m.\u001b[39min_type, nz_tangents)\n\u001b[0;32m--> 335\u001b[0m result \u001b[39m=\u001b[39m call_primitive\u001b[39m.\u001b[39;49mbind(f_jvp, \u001b[39m*\u001b[39;49mprimals, \u001b[39m*\u001b[39;49mnonzero_tangents, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_params)\n\u001b[1;32m    336\u001b[0m primal_out, tangent_out \u001b[39m=\u001b[39m tree_unflatten(out_tree_def(), result)\n\u001b[1;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m [JVPTracer(\u001b[39mself\u001b[39m, p, t) \u001b[39mfor\u001b[39;00m p, t \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(primal_out, tangent_out)]\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1765\u001b[0m, in \u001b[0;36mCallPrimitive.bind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, fun, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m-> 1765\u001b[0m   \u001b[39mreturn\u001b[39;00m call_bind(\u001b[39mself\u001b[39;49m, fun, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1781\u001b[0m, in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1779\u001b[0m tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(top_trace\u001b[39m.\u001b[39mfull_raise, args)\n\u001b[1;32m   1780\u001b[0m fun_ \u001b[39m=\u001b[39m lu\u001b[39m.\u001b[39mannotate(fun_, fun\u001b[39m.\u001b[39min_type)\n\u001b[0;32m-> 1781\u001b[0m outs \u001b[39m=\u001b[39m top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params)\n\u001b[1;32m   1782\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, apply_todos(env_trace_todo(), outs))\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/interpreters/partial_eval.py:213\u001b[0m, in \u001b[0;36mJaxprTrace.process_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    210\u001b[0m const_params \u001b[39m=\u001b[39m update_params(params, in_knowns, \u001b[39m0\u001b[39m)\n\u001b[1;32m    212\u001b[0m \u001b[39m# Run the call, getting known out vals and aux data used for staged-out call\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m out \u001b[39m=\u001b[39m primitive\u001b[39m.\u001b[39;49mbind(_update_annotation(f_, f\u001b[39m.\u001b[39;49min_type, in_knowns),\n\u001b[1;32m    214\u001b[0m                      \u001b[39m*\u001b[39;49min_consts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconst_params)\n\u001b[1;32m    215\u001b[0m out_knowns, out_avals, jaxpr, env \u001b[39m=\u001b[39m aux()\n\u001b[1;32m    216\u001b[0m \u001b[39m# Split apart known outputs from the original call and residuals.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1765\u001b[0m, in \u001b[0;36mCallPrimitive.bind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, fun, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m-> 1765\u001b[0m   \u001b[39mreturn\u001b[39;00m call_bind(\u001b[39mself\u001b[39;49m, fun, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:1781\u001b[0m, in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1779\u001b[0m tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(top_trace\u001b[39m.\u001b[39mfull_raise, args)\n\u001b[1;32m   1780\u001b[0m fun_ \u001b[39m=\u001b[39m lu\u001b[39m.\u001b[39mannotate(fun_, fun\u001b[39m.\u001b[39min_type)\n\u001b[0;32m-> 1781\u001b[0m outs \u001b[39m=\u001b[39m top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params)\n\u001b[1;32m   1782\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, apply_todos(env_trace_todo(), outs))\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/core.py:678\u001b[0m, in \u001b[0;36mEvalTrace.process_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_call\u001b[39m(\u001b[39mself\u001b[39m, primitive, f, tracers, params):\n\u001b[0;32m--> 678\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(f, \u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/dispatch.py:185\u001b[0m, in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    182\u001b[0m compiled_fun \u001b[39m=\u001b[39m _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[1;32m    183\u001b[0m                              keep_unused, \u001b[39m*\u001b[39marg_specs)\n\u001b[1;32m    184\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m   \u001b[39mreturn\u001b[39;00m compiled_fun(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFloatingPointError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m   \u001b[39massert\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_nans \u001b[39mor\u001b[39;00m config\u001b[39m.\u001b[39mjax_debug_infs  \u001b[39m# compiled_fun can only raise in this case\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jax/lib/python3.9/site-packages/jax/_src/dispatch.py:615\u001b[0m, in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, input_handler, output_buffer_counts, result_handlers, effects, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m effects:\n\u001b[1;32m    614\u001b[0m   input_bufs_flat, token_handler \u001b[39m=\u001b[39m _add_tokens(effects, device, input_bufs_flat)\n\u001b[0;32m--> 615\u001b[0m out_bufs_flat \u001b[39m=\u001b[39m compiled\u001b[39m.\u001b[39;49mexecute(input_bufs_flat)\n\u001b[1;32m    616\u001b[0m check_special(name, out_bufs_flat)\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m output_buffer_counts \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Simultaniously fit the policy nn and the particle filter nn, given some observed data\n",
    "def pf_training_loop(pf_params, pl_params, data, tol=1e-6, max_iter=10**6, batch_size=128, particles=128):\n",
    "    key = jax.random.PRNGKey(1)\n",
    "    pf_opt_init, pf_opt_update, pf_get_params = adam(step_size=1.)\n",
    "    pl_opt_init, pl_opt_update, pl_get_params = adam(step_size=0.01)\n",
    "    \n",
    "    pf_opt_state = pf_opt_init(pf_params)\n",
    "    pl_opt_state = pl_opt_init(pl_params)\n",
    "    \n",
    "    agg_states, struct_params, key = generate_random_state(pl_params, key, n_forward=0, batch_size=batch_size, struct_params=None)\n",
    "\n",
    "    pf_loss = jnp.inf\n",
    "    pl_loss = jnp.inf\n",
    "    loss = jnp.inf\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while loss > tol and i < max_iter:\n",
    "        keys = jax.random.split(key, 2 * batch_size + 1)\n",
    "\n",
    "        # Update the policy nn parameters\n",
    "        pl_params = pl_get_params(pl_opt_state)\n",
    "        val, pl_grad = jax.value_and_grad(batch_loss, has_aux=True)(pl_params, struct_params, agg_states, keys[:batch_size])\n",
    "        pl_loss = val[0]\n",
    "        c_star_rel = val[1][-1]\n",
    "        if not (c_star_rel < 1).all():\n",
    "            print(jnp.concatenate((c_star_rel, struct_params[sample[0], :3]), axis=1))\n",
    "            print('Invalid consumption choices observed') \n",
    "            break\n",
    "        if jnp.isnan(pl_loss):\n",
    "            print('Loss is nan')\n",
    "            break\n",
    "        pl_opt_state = pl_opt_update(i, pl_grad, pl_opt_state)\n",
    "\n",
    "        # Update the particle filter nn parameters\n",
    "        if i > 100:\n",
    "            pl_params = pl_get_params(pl_opt_state)\n",
    "            pf_params = pf_get_params(pf_opt_state)\n",
    "            pf_loss, pf_grad = jax.value_and_grad(pf_batch_loss)(pf_params, pl_params, struct_params, data, keys[batch_size:2*batch_size], particles=particles)\n",
    "            \n",
    "            if jnp.isnan(pf_loss) or any([jnp.isnan(x).any() for x in pf_grad.values()]):\n",
    "                print('Particle Filter Loss was nan')\n",
    "                break\n",
    "            pf_opt_state = pf_opt_update(i, pf_grad, pf_opt_state)\n",
    "        \n",
    "        key = keys[-1]\n",
    "        i += 1\n",
    "        loss = pf_loss + pl_loss\n",
    "        # Simulate states forward, and generate new batch of struct_params\n",
    "        if i % 10 == 0:\n",
    "            agg_states, struct_params, key = generate_random_state(pl_params, key, n_forward=N_FORWARD, batch_size=batch_size, struct_params=None)\n",
    "\n",
    "        if i % 100 == 0 or i > 100:\n",
    "            print(f'Iteration: {i}\\tPolicy Loss: {pl_loss:.2e}\\tParticle Filter Loss: {pf_loss:.2e}')\n",
    "    \n",
    "    return get_params(pf_opt_state), get_params(pl_opt_state)\n",
    "    \n",
    "\n",
    "pf_params, pl_params = pf_training_loop(pf_params0, range_params, cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e15667f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 200\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 300\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 400\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 500\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 600\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 700\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 800\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 900\tParticle Filter Loss: 1.00e+04\n",
      "Iteration: 1000\tParticle Filter Loss: 1.00e+04\n"
     ]
    }
   ],
   "source": [
    "# Fit the particle filter neural network to a predefined set of ll observations\n",
    "@jax.jit\n",
    "def temp_batch_loss(params, struct_params, lls):\n",
    "    preds = jax.vmap(particle_neural_network, in_axes=(None, 0))(params, struct_params)\n",
    "    return jnp.mean((preds - lls)**2)\n",
    "\n",
    "\n",
    "def pf_training_loop(pf_params, struct_params, lls, tol=1e-6, max_iter=1000, batch_size=128, particles=128):\n",
    "    key = jax.random.PRNGKey(1)\n",
    "    pf_opt_init, pf_opt_update, pf_get_params = adam(step_size=0.01)\n",
    "    pf_opt_state = pf_opt_init(pf_params)\n",
    "\n",
    "    pf_loss = jnp.inf\n",
    "    i = 0\n",
    "\n",
    "    while pf_loss > tol and i < max_iter:\n",
    "        keys = jax.random.split(key, batch_size)\n",
    "\n",
    "        sample = jax.random.choice(key, struct_params.shape[0], shape=(batch_size,))\n",
    "        # pf_params = pf_get_params(pf_opt_state)\n",
    "        pf_loss, pf_grad = jax.value_and_grad(temp_batch_loss)(pf_params, struct_params, lls)\n",
    "        \n",
    "        if jnp.isnan(pf_loss) or any([jnp.isnan(x).any() for x in pf_grad.values()]):\n",
    "            print('Particle Filter Loss was nan')\n",
    "            break\n",
    "        \n",
    "        pf_params = {k: pf_params[k] - (1/(i+1)) * pf_grad[k] for k in pf_params.keys()}\n",
    "        # pf_opt_state = pf_opt_update(i, pf_grad, pf_opt_state)\n",
    "        \n",
    "        _, key = jax.random.split(key, 2)\n",
    "        i += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration: {i}\\tParticle Filter Loss: {pf_loss:.2e}')\n",
    "    \n",
    "    return pf_params # pf_get_params(pf_opt_state)\n",
    "    \n",
    "\n",
    "pf_params = pf_training_loop(pf_params0, struct_params, lls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c92a92",
   "metadata": {},
   "source": [
    "## Plotting Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, get_params = adam(step_size=0.001)\n",
    "saved_state = pickle.load(open(f'./ks_cont_models/ks_cont_model_{K}_990.pkl', 'rb'))\n",
    "opt_state = pack_optimizer_state(saved_state)\n",
    "params = get_params(opt_state)\n",
    "\n",
    "key = jax.random.PRNGKey(np.random.randint(1, int(1e8)))\n",
    "keys = jax.random.split(key, N // 2)\n",
    "Xs, Zs, Es, struct_params, key = generate_random_state(params, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41c702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(np.random.randint(1, int(1e8)))\n",
    "idx = jax.random.choice(key, jnp.arange(N), shape=(5,))\n",
    "\n",
    "X = Xs\n",
    "Z = Zs\n",
    "E = Es\n",
    "e = E[:, 0]\n",
    "\n",
    "# x_range = jnp.linspace(jnp.min(ws), jnp.max(ws), 100)\n",
    "x_range = jnp.linspace(0, 10, 100)\n",
    "c_range = jax.vmap(lambda X, E, Z, e: jax.vmap(lambda x: neural_network(params, STRUCT_PARAM_ARR, X, E, Z, e, x)[0])(x_range))(X, Z, E, e)\n",
    "data = pd.DataFrame(jnp.concatenate((x_range.reshape(-1, 1), c_range.T), axis=1), dtype=np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "_ = data.plot(x=0, y=jnp.arange(Xs.shape[0]) + 1, ax=ax, legend=False)\n",
    "_ = fig.suptitle(f'Optimal consumption (as a function of idiosyncratic state) across some aggregate states drawn from the ergodic distribution', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803e664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(np.random.randint(1, int(1e8)))\n",
    "idx = jax.random.choice(key, jnp.arange(N), shape=(5,))\n",
    "\n",
    "X = Xs[0]\n",
    "Z = Zs[0]\n",
    "E = Es[0]\n",
    "e = E[0]\n",
    "\n",
    "# x_range = jnp.linspace(jnp.min(ws), jnp.max(ws), 100)\n",
    "x_range = jnp.linspace(0, 10, 100)\n",
    "c_range = jax.vmap(lambda config: jax.vmap(lambda x: neural_network(params, config, X, E, Z, e, x)[0])(x_range))(struct_params)\n",
    "\n",
    "data = pd.DataFrame(jnp.concatenate((x_range.reshape(-1, 1), c_range.T), axis=1), dtype=np.float32)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "_ = data.plot(x=0, y=jnp.arange(struct_params.shape[0]) + 1, ax=ax, legend=False)\n",
    "_ = fig.suptitle(f'Optimal consumption (as a function of idiosyncratic state) across some structural parameters drawn', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a63b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.tree_util.Partial(jax.jit, static_argnums=(0,))\n",
    "def generate_struct_param_range(size=1000):\n",
    "    abd = jnp.array(jnp.meshgrid(jnp.linspace(0, 1, size), jnp.linspace(0, 1, size), jnp.linspace(0, 1, size))).T.reshape(-1, 3)\n",
    "    a = STRUCT_PARAM['a'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    b = STRUCT_PARAM['b'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    rho_z = STRUCT_PARAM['rho_z'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    rho_e = STRUCT_PARAM['rho_e'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    sigma_z = STRUCT_PARAM['sigma_z'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    sigma_e = STRUCT_PARAM['sigma_e'] * jnp.ones((jnp.power(size, 3.).astype(jnp.int32), 1))\n",
    "    \n",
    "    struct_params = jnp.concatenate((abd, a, b, rho_z, rho_e, sigma_z, sigma_e), axis=1)\n",
    "        \n",
    "    return struct_params\n",
    "\n",
    "\n",
    "# @jax.jit\n",
    "def next_c(model_params, struct_params, agg_state):\n",
    "    R, W = prices(struct_params, agg_state)\n",
    "    w = jnp.squeeze(jax.vmap(lambda x, e: (R * x) + (W * jnp.exp(e)))(agg_state[AGG_IDXS['Xs']], agg_state[AGG_IDXS['Es']]))\n",
    "    ido_state = jnp.concatenate((agg_state[AGG_IDXS['Es']], jnp.squeeze(w))).reshape(5, 2, -1)\n",
    "    out = jax.vmap(neural_network, in_axes=(None, None, None, 0))(model_params, struct_params, agg_state, ido_state)\n",
    "    c = jnp.squeeze(w * out[..., 0])\n",
    "    return c\n",
    "\n",
    "    \n",
    "# @jax.jit\n",
    "def simulate_state_forward(model_params, struct_params, agg_states, key):\n",
    "    keys = jax.random.split(key, N_FORWARD * agg_states.shape[0]).reshape(N_FORWARD, agg_states.shape[0], 2)\n",
    "    \n",
    "    # @jax.jit\n",
    "    def inner_loop(agg_states, i):\n",
    "        return jax.vmap(next_state, in_axes=(None, None, 0, 0))(model_params, struct_params, agg_states, keys[i]), None\n",
    "    \n",
    "    agg_states, _ = jax.lax.scan(inner_loop, agg_states, jnp.arange(N_FORWARD))\n",
    "    \n",
    "    return agg_states, keys[-1, -1]\n",
    "\n",
    "\n",
    "# @jax.tree_util.Partial(jax.jit, static_argnums=(2,))\n",
    "def generate_sim_states(model_params, key, size=1000):\n",
    "    n_rows = jnp.power(size, 3)\n",
    "    keys = jax.random.split(key, n_rows)\n",
    "    struct_params = generate_struct_param_range(size=size)\n",
    "    \n",
    "    Zs = jnp.ones(shape=(MB,))\n",
    "    Es = jnp.ones(shape=(MB, K))\n",
    "    Xs = jnp.exp(STRUCT_PARAM['a'] * jax.random.normal(\n",
    "         jax.random.PRNGKey(np.random.randint(1, int(1e8))), \n",
    "         shape=(MB, K))) + STRUCT_PARAM['b']\n",
    "    \n",
    "    agg_states = jnp.concatenate((Xs, Es, Zs.reshape(-1, 1)), axis=1)\n",
    "    \n",
    "    if N_FORWARD > 0:\n",
    "        agg_states, keys = jax.vmap(lambda struct_param, key: simulate_state_forward(model_params, struct_param, agg_states, key))(struct_params, keys)\n",
    "    \n",
    "    cs = jax.vmap(jax.vmap(next_c, in_axes=(None, 0, 0)), in_axes=(None, None, 1))(model_params, struct_params, agg_states)\n",
    "    \n",
    "    return cs\n",
    "\n",
    "\n",
    "cs = generate_sim_states(params0, jax.random.PRNGKey(1), size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0d3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = jnp.array([[3., 3., 2.], [0., 1., 0.], [4., 2., 1.]])\n",
    "jax.scipy.stats.multivariate_normal.logpdf(diffs, mean=jnp.ones(3), cov=jnp.diag(jnp.ones(3) / MB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('jax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e8d6a125da418167969c6dc54453845370be835253818021d0824830614882a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
